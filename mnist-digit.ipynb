{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualize the digits\n",
    "\n",
    "Let us look at some random digits from the training sample and their respective labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 6\n",
    "m = train.shape[0]\n",
    "idx = np.random.choice(m, size=num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 2\n",
    "num_cols = 3\n",
    "\n",
    "fig, ax = plt.subplots(nrows = num_rows, ncols = num_cols)\n",
    "fig.set_size_inches(12,10)\n",
    "\n",
    "for i, j in enumerate(idx):\n",
    "    # Find the right place to put the images, a is the row in the figure and b is the column\n",
    "    \n",
    "    a = i//num_cols\n",
    "    b = i%num_cols\n",
    "\n",
    "    # Remove ticks\n",
    "    \n",
    "    ax[a][b].tick_params(\n",
    "    which='both',\n",
    "    left=False,\n",
    "    right=False,\n",
    "    bottom=False,\n",
    "    top=False,\n",
    "    labelleft = False,\n",
    "    labelbottom=False)\n",
    "    \n",
    "    # Draw image and set x label as the actual label of the image i.e. the value of the digit in the image\n",
    "    \n",
    "    ax[a][b].imshow(np.array(train.loc[j][1:]).reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "    ax[a][b].set_xlabel(str(train.loc[j][0]), fontsize = 50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Convert data to the right shape for CNN\n",
    "\n",
    "Convert the flattened arrays to image arrays, normalize by dividing by 255 and separate features (X) from labels (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((m,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(train.label)\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y]\n",
    "    return Y\n",
    "\n",
    "y = convert_to_one_hot(y,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "\n",
    "seed = 5\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Get random training index\n",
    "\n",
    "train_index = np.random.choice(m, round(m*0.9), replace=False)\n",
    "dev_index = np.array(list(set(range(m)) - set(train_index)))\n",
    "\n",
    "# Make training and dev\n",
    "\n",
    "X_train = X[train_index]\n",
    "X_dev = X[dev_index]\n",
    "\n",
    "y_train = y[train_index]\n",
    "y_dev = y[dev_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_test = test.shape[0]\n",
    "X_test = np.array(test).reshape((m_test,28,28,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.\n",
    "X_dev = X_dev/255.\n",
    "X_test = X_test/255.\n",
    "X_test = np.float32(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of validation \\(dev\\) examples = \" + str(X_dev.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"y_train shape: \" + str(y_train.shape))\n",
    "print (\"X_dev shape: \" + str(X_dev.shape))\n",
    "print (\"y_dev shape: \" + str(y_dev.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Apply LeNet 5 architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LeNet architecture we will apply is as follows:\n",
    "\n",
    "INPUT => CONV (28x28x20, f = 5, s = 1) => RELU => POOL (14x14x20, f = 2, s = 2) => CONV (14x14x50, f = 5, s = 1) => RELU => POOL (7x7x50, f = 2, s = 2) + flatten => FC (120) => RELU => FC (84) => softmax\n",
    "\n",
    "Thus, there are 2 conv layers and 2 pooling layers. Then 2 fully connected layers with ReLU activation and the final layer with a softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Placeholders\n",
    "\n",
    "def create_placeholders(n_H0,n_W0,n_C0,n_y):\n",
    "    X = tf.placeholder(dtype = tf.float32,shape = [None, n_H0, n_W0, n_C0])\n",
    "    Y = tf.placeholder(dtype = tf.float32,shape = [None, n_y])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    tf.set_random_seed(1)\n",
    "    initializer = tf.contrib.layers.xavier_initializer(seed = 0)\n",
    "    W1 = tf.get_variable(name = 'W1', shape = [5, 5, 1, 20], initializer = initializer)\n",
    "    W2 = tf.get_variable(name = 'W2', shape = [5, 5, 20, 50], initializer = initializer)\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check parameters\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess_test:\n",
    "    parameters = initialize_parameters()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess_test.run(init)\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"].eval()[1,1,0]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"].eval()[1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build forward propagation computation graph\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    " \n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    Z1 = tf.nn.conv2d(X,W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    # MAXPOOL: window 2x2, stride 2, padding 'VALID'\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    Z2 = tf.nn.conv2d(P1,W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    # MAXPOOL: window 2x2, stride 2, padding 'VALID'\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "    # FLATTEN\n",
    "    P2 = tf.contrib.layers.flatten(P2)\n",
    "    # FULLY-CONNECTED \n",
    "    Z3 = tf.contrib.layers.fully_connected(P2, 120)\n",
    "    # FULLY-CONNECTED \n",
    "    Z4 = tf.contrib.layers.fully_connected(Z3, 84)\n",
    "    # FULLY-CONNECTED \n",
    "    Z5 = tf.contrib.layers.fully_connected(Z4, 10, activation_fn = tf.nn.softmax)\n",
    "    \n",
    "    return Z5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check forward propagation\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X, Y = create_placeholders(28, 28, 1, 10)\n",
    "    parameters = initialize_parameters()\n",
    "    Z5 = forward_propagation(X, parameters)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(Z5, {X: np.random.randn(2,28,28,1), Y: np.random.randn(2,10)})\n",
    "    print(\"Z5 = \" + str(a))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Cost\n",
    "\n",
    "def compute_cost(Z5, Y):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z5, labels = Y))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check cost function\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X, Y = create_placeholders(28, 28, 1, 10)\n",
    "    parameters = initialize_parameters()\n",
    "    Z5 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z5, Y)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(cost, {X: np.random.randn(4,28,28,1), Y: np.random.randn(4,10)})\n",
    "    print(\"cost = \" + str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters and optimization function\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, X_test, y_train, learning_rate = learning_rate, num_epochs = num_epochs, batch_size = batch_size, print_cost = True):\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    (m_train, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    num_batches = (m_train//batch_size) + 1\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    \n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "    \n",
    "\n",
    "    # Initialize parameters\n",
    "    \n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    \n",
    "    Z5 = forward_propagation(X, parameters)\n",
    "    \n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    \n",
    "    cost = compute_cost(Z5, Y)\n",
    "    \n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "  \n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Generate random batch index\n",
    "            minibatch_cost = 0\n",
    "            full_batch = range(m_train)\n",
    "\n",
    "            for batch in range(num_batches):        \n",
    "                try:\n",
    "                    batch_index = np.random.choice(full_batch, size=batch_size, replace = False)\n",
    "                    full_batch = np.array(list(set(full_batch) - set(batch_index)))\n",
    "                except ValueError:\n",
    "                    batch_index = full_batch\n",
    "                batch_train_X = X_train[batch_index]\n",
    "                batch_train_y = y_train[batch_index]\n",
    "\n",
    "                # Run session to reach goal \n",
    "\n",
    "                sess.run(optimizer, feed_dict={X: batch_train_X, Y: batch_train_y})\n",
    "                temp_cost = sess.run(cost, feed_dict={X: batch_train_X, Y: batch_train_y})\n",
    "                minibatch_cost += temp_cost / num_batches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            \n",
    "            print (\"Cost after epoch %i: %f\" % (epoch+1, minibatch_cost))\n",
    "            costs.append(minibatch_cost)\n",
    "\n",
    "\n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z5, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "      \n",
    "        # Calculate accuracy on the train and dev sets\n",
    "        \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: y_train})\n",
    "        dev_accuracy = accuracy.eval({X: X_dev, Y: y_dev})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Dev Accuracy:\", dev_accuracy)\n",
    "        \n",
    "        # Make predictions on test set\n",
    "        \n",
    "        test_preds = sess.run(predict_op, feed_dict ={X:X_test})\n",
    "        \n",
    "        return train_accuracy, dev_accuracy, parameters, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy, dev_accuracy, parameters, test_preds = model(X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Check random sample prediction from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.choice(m_test)\n",
    "print(\"Test sample no.: {}\".format(i))\n",
    "\n",
    "print('Prediction: {}'.format(test_preds[i]))\n",
    "plt.imshow(X_test[i,:,:,0],cmap = plt.get_cmap('gray'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Write submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Label'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['ImageId'] = list(range(1,m_test+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['ImageId', 'Label']].to_csv('submission_lenet5.csv', index = False, header = ['ImageId','Label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
